{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Retrieval   |    Assignment 1-B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_table('YandexRelPredChallenge.txt', delimiter=\"\\t\",index_col=None, \n",
    "                 header=0,names=['SessionID', 'TimePassed','TypeOfAction', 'QueryID','RegionID', 'ListOfURLs', 'URLID',\n",
    "                                 '1','2','3','4','5',\"6\",'7','8'])\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open file    \n",
    "fileHandler = open ('YandexRelPredChallenge.txt', \"r\")\n",
    "# Get list of all lines in file\n",
    "listOfLines = fileHandler.readlines()\n",
    "# Close file \n",
    "fileHandler.close()\n",
    "#Empty frame to fill in\n",
    "index=[x for x in range(0,100000)]\n",
    "df = pd.DataFrame(index=index, columns=['SessionID', 'TimePassed',\n",
    "                 'TypeOfAction', 'QueryID','RegionID', 'ListOfURLs', 'URLID'])\n",
    "df.name='data'\n",
    "\n",
    "# Iterate over the lines and fill in the dataframe\n",
    "for ind, line in zip(index, listOfLines):\n",
    "#     print('index')\n",
    "    line = line.strip().split()\n",
    "    if line[2]=='Q':\n",
    "\n",
    "        df.loc[ind] = pd.Series({'SessionID':line[0], 'TimePassed':line[1], 'TypeOfAction':line[2],\n",
    "                                     'QueryID':line[3],'RegionID':line[4], 'ListOfURLs':line[5:], 'URLID':np.nan})\n",
    "    else:\n",
    "        df.loc[ind] = pd.Series({'SessionID':line[0], 'TimePassed':line[1], 'TypeOfAction':line[2],\n",
    "                                     'QueryID':np.nan,'RegionID':np.nan, 'ListOfURLs':np.nan, 'URLID':line[3:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the types right. \n",
    "df.SessionID = df.SessionID.astype(int)\n",
    "df.TimePassed = df.TimePassed.astype(int)\n",
    "df.TypeOfAction = df.TypeOfAction.astype(str)\n",
    "df.RegionID = df.RegionID.astype(float)\n",
    "df.TimePassed = df.TimePassed.astype(float)\n",
    "def parse_ulrid(x):\n",
    "    if type(x)==list:\n",
    "        return x[0]\n",
    "    else:\n",
    "        return x\n",
    "df.URLID = df.URLID.apply(parse_ulrid)\n",
    "df.URLID = df.URLID.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new relevance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets say that our experimental system is what Yandex return as a list now. Production or the system that is going to 'suck' (sort of a dumb system that we are going to compare against) will be constructed as shuffling each ranking for a query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, other approach, probably the better one: take the initial order as the 'benchmark' create only list of 0,1 (relevnace scores) for each system.\n",
    "    - rember that we are interested only in three [3] first results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the relevance score ranking (those tables = that we called 'runs')\n",
    "def relevance_list(l,acc=0.5, res_length=3):\n",
    "    \"\"\" Control the 'accuracy'/'performance' with acc param. Only lists of length 3. \"\"\"\n",
    "    if type(l)==list:\n",
    "        res = list()\n",
    "        for x in l:\n",
    "            if rnd.random()<acc:\n",
    "                res.append((x, 1))\n",
    "            else:\n",
    "                res.append((x, 0))\n",
    "        return rnd.sample(res, res_length)\n",
    "    else:\n",
    "        return l\n",
    "\n",
    "df['id_rel_e'] = df.ListOfURLs.apply(relevance_list, acc=0.7) \n",
    "df['id_rel_p'] = df.ListOfURLs.apply(relevance_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rel(l):\n",
    "    if type(l) == list:\n",
    "        res = list()\n",
    "        for tup in l:\n",
    "            res.append(tup[1])\n",
    "        return res\n",
    "    else:\n",
    "        return l\n",
    "def extract_id(l):\n",
    "    if type(l) == list:\n",
    "        res = list()\n",
    "        for tup in l:\n",
    "            res.append(tup[0])\n",
    "        return res\n",
    "    else:\n",
    "        return l\n",
    "df['rel_e'] = df.id_rel_e.apply(extract_rel)\n",
    "df['rel_p'] = df.id_rel_p.apply(extract_rel)\n",
    "df['id_e'] = df.id_rel_e.apply(extract_id)\n",
    "df['id_p'] = df.id_rel_p.apply(extract_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Calculate ERR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see the formuala for ERR at: http://olivier.chapelle.cc/pub/err.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ERR(l):\n",
    "    \"\"\" List or relevance scores. \"\"\" \n",
    "    if type(l)==list:\n",
    "        theta = [ (2**i - 1)/(2) for i in [0,1]]\n",
    "        err=0\n",
    "        for rank in range(len(l)):\n",
    "            prod = 1\n",
    "            for idx in range(rank):\n",
    "                prod*=(1-theta[l[idx]])\n",
    "            prod*=(1/(rank+1))*theta[l[rank]]\n",
    "            err+=prod\n",
    "        return err\n",
    "    else:\n",
    "        return l\n",
    "df['err_e'] = df.rel_e.apply(ERR)\n",
    "df['err_p'] = df.rel_p.apply(ERR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if ERR calculation is implemented correctly and if E outperfroms P \n",
    "import math \n",
    "df['diff_e_p'] = df.err_e - df.err_p\n",
    "def count_t(x):\n",
    "    if not math.isnan(x):\n",
    "        if x>0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0 \n",
    "    else:\n",
    "        return x \n",
    "df['temp_count'] = df.diff_e_p.apply(count_t)\n",
    "df.loc[:,['diff_e_p', 'temp_count']]\n",
    "df.temp_count.value_counts()\n",
    "df.drop(columns=['diff_e_p','temp_count'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Estimating the params of click models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13445559411047547\n"
     ]
    }
   ],
   "source": [
    "# Get all the doc ids\n",
    "data = df.drop(columns=['id_rel_e', 'id_rel_p', 'rel_e', 'rel_p', 'id_e',\n",
    "       'id_p', 'err_e', 'err_p'])\n",
    "list_doc_ids_raw = data.ListOfURLs[df.ListOfURLs.isnull()!=True].values\n",
    "res = list()\n",
    "for i in list_doc_ids_raw:\n",
    "    res += i\n",
    "all_doc_ids = res.copy()\n",
    "# Get all the clicks\n",
    "list_clicks_ids = data.URLID[df.URLID.isnull()!=True].values\n",
    "\n",
    "# rho = probability of a doc to be clicked.\n",
    "rho = len(list_clicks_id)/len(all_doc_ids)\n",
    "print(rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
